services:
  localstack:
    container_name: ${LOCALSTACK_CONTAINER_NAME}
    image: localstack/localstack:3.0.0
    ports:
      - "4566:4566" # LocalStack Gateway
    environment:
      - DEBUG=1
      - services=s3,ssm,dynamodb,sqs
      - LAMBDA_EXECUTOR=local
      - DOCKER_HOST=unix:///var/run/docker.sock
    volumes:
      - "${LOCALSTACK_VOLUME_DIR:-./volume}:/var/lib/localstack"
      - "/var/run/docker.sock:/var/run/docker.sock"
    env_file:
      - .env
  terraform:
    container_name: ${TERRAFORM_CONTAINER_NAME}
    image: hashicorp/terraform
    entrypoint: [ "/bin/sh" ]
    command: -c "terraform init && terraform apply --auto-approve"
    volumes:
      - "./main.tf:/main.tf"
    depends_on:
      - localstack
    env_file:
      - .env
  postgres:
    container_name: ${POSTGRES_CONTAINER_NAME}
    image: postgres:13.12
    restart: always
    ports:
      - "5432:5432"
    volumes:
      #      - "postgres_data:/var/lib/postgresql/data"
      - "./scripts/db/deployment:/docker-entrypoint-initdb.d"
    env_file:
      - .env
  spark-master:
    container_name: ${SPARK_MASTER_CONTAINER_NAME}
    image: apache/spark:3.5.6-scala2.12-java17-python3-r-ubuntu
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    env_file:
      - .env
    ports:
      - "8080:8080"
      - "7077:7077"
      - "4040:4040"
    volumes:
      - "./src/:/opt/spark/work-dir"
      - "${HOME}/.aws/:/opt/spark/.aws:ro"
      - "./volume/tmp/:/tmp/"
      - "./volume/h-s/:/tmp/hadoop-spark/"
      - "./volume/h-s-a/:/tmp/hadoop-spark/s3a"
      - "./config/spark/:/opt/spark/conf/"
      - "./local/jars/:/opt/spark/ivy/"
    depends_on:
      localstack:
        condition: service_started
      postgres:
        condition: service_started
  spark-worker-1:
    container_name: spark-worker-1
    image: apache/spark:3.5.6-scala2.12-java17-python3-r-ubuntu
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    env_file:
      - .env
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      spark-master:
        condition: service_started
  spark-worker-2:
    container_name: spark-worker-2
    image: apache/spark:3.5.6-scala2.12-java17-python3-r-ubuntu
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    env_file:
      - .env
    depends_on:
      spark-master:
        condition: service_started
  spark-client:
    build:
      context: .
      dockerfile: Dockerfile.spark-client
    container_name: spark-client
    volumes:
      - .:/app
    command: ["sleep", "infinity"]
    depends_on:
      spark-worker-1:
        condition: service_started
      spark-worker-2:
        condition: service_started